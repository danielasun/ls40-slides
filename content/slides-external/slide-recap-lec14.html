<section>
	<h3>Last time</h3>
	<p class="u em down-3">
		Errors in statistical studies:
	</p>
	<ul class="small">
		<li>
			<span class="strong">Type 1</span>: false positive (reject the null when the null is true). $[\alpha]$
		</li>
		<li>
			<span class="strong">Type 2</span>: false negative (fail to reject the null when the null is false). $[\beta]$
		</li>
	</ul>
	<p>
		<span class="strong">Power</span>: correctly reject the null when the null is false (increase the sample size to get more statistical power). $[1-\beta]$
	</p>
	<p class="down-3">
		Reporting effect size and confidence intervals of the effect size lets us put our result in context (<span class="em info">statistical significance</span> vs <span class="em danger">practical significance</span>), while reporting only p-value does not. 
	</p>
	<p class="down-3">
		Multi-testing problem. <br>
		Publication biais problem (more chances to publish statistically significant results).
	</p>
</section>

<section data-external-replace="slide-animation-errors-power.html"></section>