<section>
  <h3>Summary</h3>
  <p class="sided border-pop">
    Conclusions based off p-values are not perfect
  </p>
  <p class="sided border-orange">
    Type I and Type II errors can happen
  </p>
  <p class="sided border-orange">
    $\alpha$ of all tests will be significant just by chance and often, only the significant results get published
  </p>
  <p class="sided border-danger">
    Replication of results is important 
  </p>
  <p class="sided border-info">
    Larger sample sizes make it easier to get significant results (more statistical <span class="strong">power</span>)
  </p>
  <p class="framed border-danger down-3">
    <i class="fa fa-arrow-circle-right danger"></i>
    Reporting the <span class="strong">effect size and its associated confidence intervals</span> along/instead of the p-value 
    gives you an estimate of the true value of your effect (treatment). <br>
    This is what is of <span class="danger">practical importance</span> <span class="em">(e.g.: Biological relevance?)</span>.
  </p>
<!--   <p >
    <span class="u em">Note:</span> for more details, see the 2016 American Statistical Associationâ€™s Statement on p-values
  </p> -->
</section>